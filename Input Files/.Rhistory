#### Define model for JAGS ####
model_string <- textConnection("model{
# Likelihood
for(i in 1:n){
Y[i] ~ dnorm(inprod(X[i,],beta[]),tau)
}
# Priors
for(j in 1:p){beta[j] ~ dnorm(0, 0.0001)}
tau ~ dgamma(0.01,0.01)
# Predictions
for (i in 1:n_pred){
Y_pred[i] ~ dnorm(inprod(X_pred[i,],beta[]),tau)
}
}")
#### Initialize model with values of theta = Y/n ####
# inits <- list(theta=y/n)
model <- jags.model(model_string,data = data,n.chains=2,quiet=TRUE)
#### Burn-in 10000 samples ####
update(model, 10000, progress.bar="none")
#### Run 10000 samples, outputing each of the beta parameters ####
params  <- c("beta", "Y_pred")
samples <- coda.samples(model,
variable.names=params,
n.iter=10000, progress.bar="none")
out <- summary(samples)$statistics
names_X <- c("Y501", "Y502", "Y503", "Y504", "Y505", "Y506", "Intercept",
"Crime Rate", "Large Res. Zoned", "% Industrial",
"Charles River Border", "NOx Conc.", "Rms/Dwelling", "% Built < 1940",
"Dis. To Hub", "Highway Accessibility", "Tax Rate", "Pupil/Teacher",
"% Black", "Pop. Status")
rownames(out) <- names_X
out
Y_pred
pbeta(10,1)
pbeta(0.7,10,1)
plot(seq(0,1,0.01),dbeta(seq(0,1,0.01),10,1))
1 - pbeta(0.7,10,1)
0.972/0.0282
knitr::opts_chunk$set(echo = TRUE)
library(rjags)
library(geoR)
Y   <- gambia$pos
X   <- gambia[,4:8]
X   <- scale(X)
mod <- textConnection("model{
for(i in 1:n){
Y[i] ~ dbern(pi[i])
logit(pi[i]) <- beta[1] + X[i,1]*beta[2] +
X[i,2]*beta[3] + X[i,3]*beta[4] +
X[i,4]*beta[5] + X[i,5]*beta[6]
}
for(j in 1:6){beta[j] ~ dnorm(0,0.01)}
}")
data  <- list(Y=Y,X=X,n=length(Y))
model <- jags.model(mod,data = data, n.chains=2,quiet=TRUE)
update(model, 5000, progress.bar="none")
samps <- coda.samples(model, variable.names=c("beta"),
n.iter=10000, progress.bar="none")
samps <- rbind(samps[[1]], samps[[2]])
S <- nrow(samps)
calc_stats <- function(data){
return(c(mean(data),var(data)))
}
D0 <- calc_stats(Y)
D <- matrix(0,S,2)
for (i in 1:S){
beta <- samps[i,]
Yp <- matrix(0,X,1)
for (x in 1:nrow(X)){
Yp[x] <- beta[1] + X[x,1]*beta[2] + X[x,2]*beta[3] + X[x,3]*beta[4] + X[x,4]*beta[5] + X[x,5]*beta[6]
}
D[s,] <- calc_stats(Yp)
}
for (i in 1:S){
beta <- samps[i,]
Yp <- matrix(0,X,1)
for (x in 1:nrow(X)){
Yp[x] <- beta[1] + X[x,1]*beta[2] + X[x,2]*beta[3] + X[x,3]*beta[4] + X[x,4]*beta[5] + X[x,5]*beta[6]
}
D[i,] <- calc_stats(Yp)
}
View(D)
names <- c("Mean", "Variance")
for(j in 1:6){
pval <- mean(D[,j]>D0[j])
hist(D[,j],breaks=25,xlim=range(D[,j]) + 1*c(-1,1),
xlab=names[j],
main=paste0("Bayesian p-value = ",round(pval,2)))
abline(v=D0[j],lwd=2,col=2)
}
for(j in 1:2){
pval <- mean(D[,j]>D0[j])
hist(D[,j],breaks=25,xlim=range(D[,j]) + 1*c(-1,1),
xlab=names[j],
main=paste0("Bayesian p-value = ",round(pval,2)))
abline(v=D0[j],lwd=2,col=2)
}
Y   <- gambia$pos
X   <- gambia[,c(4,5,7)]
X   <- scale(X)
mod <- textConnection("model{
for(i in 1:n){
Y[i] ~ dbern(pi[i])
logit(pi[i]) <- beta[1] + X[i,1]*beta[2] +
X[i,2]*beta[3] + X[i,3]*beta[4] +
X[i,4]*beta[5] + X[i,5]*beta[6]
}
for(j in 1:6){beta[j] ~ dnorm(0,0.01)}
}")
data  <- list(Y=Y,X=X,n=length(Y))
model <- jags.model(mod,data = data, n.chains=2,quiet=TRUE)
Y   <- gambia$pos
X   <- gambia[,c(4,5,7)]
X   <- scale(X)
mod <- textConnection("model{
for(i in 1:n){
Y[i] ~ dbern(pi[i])
logit(pi[i]) <- beta[1] + X[i,1]*beta[2] +
X[i,2]*beta[3] + X[i,3]*beta[4]
}
for(j in 1:4){beta[j] ~ dnorm(0,0.01)}
}")
data  <- list(Y=Y,X=X,n=length(Y))
model <- jags.model(mod,data = data, n.chains=2,quiet=TRUE)
update(model, 1000, progress.bar="none")
samps <- coda.samples(model, variable.names=c("beta"),
n.iter=10000, progress.bar="none")
samps <- rbind(samps[[1]], samps[[2]])
S <- nrow(samps)
calc_stats <- function(data){
return(c(mean(data),var(data)))
}
D0 <- calc_stats(Y)
D <- matrix(0,S,2)
for (i in 1:S){
beta <- samps[i,]
Yp <- matrix(0,X,1)
for (x in 1:nrow(X)){
Yp[x] <- beta[1] + X[x,1]*beta[2] + X[x,2]*beta[3] + X[x,3]*beta[4] + X[x,4]*beta[5] + X[x,5]*beta[6]
}
D[i,] <- calc_stats(Yp)
}
Y   <- gambia$pos
X   <- gambia[,c(4,5,7)]
X   <- scale(X)
mod <- textConnection("model{
for(i in 1:n){
Y[i] ~ dbern(pi[i])
logit(pi[i]) <- beta[1] + X[i,1]*beta[2] +
X[i,2]*beta[3] + X[i,3]*beta[4]
}
for(j in 1:4){beta[j] ~ dnorm(0,0.01)}
}")
data  <- list(Y=Y,X=X,n=length(Y))
model <- jags.model(mod,data = data, n.chains=2,quiet=TRUE)
update(model, 1000, progress.bar="none")
samps <- coda.samples(model, variable.names=c("beta"),
n.iter=10000, progress.bar="none")
samps <- rbind(samps[[1]], samps[[2]])
S <- nrow(samps)
calc_stats <- function(data){
return(c(mean(data),var(data)))
}
D0 <- calc_stats(Y)
D <- matrix(0,S,2)
for (i in 1:S){
beta <- samps[i,]
Yp <- matrix(0,X,1)
for (x in 1:nrow(X)){
Yp[x] <- beta[1] + X[x,1]*beta[2] + X[x,2]*beta[3] + X[x,3]*beta[4]
}
D[i,] <- calc_stats(Yp)
}
names <- c("Mean", "Variance")
for(j in 1:2){
pval <- mean(D[,j]>D0[j])
hist(D[,j],breaks=25,xlim=range(D[,j]) + 1*c(-1,1),
xlab=names[j],
main=paste0("Bayesian p-value = ",round(pval,2)))
abline(v=D0[j],lwd=2,col=2)
}
View(samps)
D0 <- calc_stats(logit(Y))
D0 <- calc_stats(log(Y/(1-Y)))
Y/(1-Y)
expit(D)
exp(D)
D <- matrix(0,S,2)
for (i in 1:S){
beta <- samps[i,]
Yp <- matrix(0,X,1)
for (x in 1:nrow(X)){
Yp[x] <- beta[1] + X[x,1]*beta[2] + X[x,2]*beta[3] + X[x,3]*beta[4]
}
D[i,] <- calc_stats(exp(Yp)/(1+exp(Yp)))
}
D0 <- calc_stats(Y)
names <- c("Mean", "Variance")
for(j in 1:2){
pval <- mean(D[,j]>D0[j])
hist(D[,j],breaks=25,xlim=range(D[,j]) + 1*c(-1,1),
xlab=names[j],
main=paste0("Bayesian p-value = ",round(pval,2)))
abline(v=D0[j],lwd=2,col=2)
}
for (i in 1:S){
beta <- samps[i,]
Yp <- matrix(0,X,1)
for (x in 1:nrow(X)){
Yp[x] <- beta[1] + X[x,1]*beta[2] + X[x,2]*beta[3] + X[x,3]*beta[4]
}
Yp <- exp(Yp)/(1+exp(Yp))
Yp_binary <- matrix(0,X,1)
for (j in 1:nrow(Yp)){
Yp_binary[j] <- rbernoulli(1, p = Yp[j])
}
D[i,] <- calc_stats(exp(Yp)/(1+exp(Yp)))
}
for (i in 1:S){
beta <- samps[i,]
Yp <- matrix(0,X,1)
for (x in 1:nrow(X)){
Yp[x] <- beta[1] + X[x,1]*beta[2] + X[x,2]*beta[3] + X[x,3]*beta[4]
}
Yp <- exp(Yp)/(1+exp(Yp))
Yp_binary <- matrix(0,X,1)
for (j in 1:length(Yp)){
Yp_binary[j] <- rbernoulli(1, p = Yp[j])
}
D[i,] <- calc_stats(exp(Yp)/(1+exp(Yp)))
}
library(purrr)
for (i in 1:S){
beta <- samps[i,]
Yp <- matrix(0,X,1)
for (x in 1:nrow(X)){
Yp[x] <- beta[1] + X[x,1]*beta[2] + X[x,2]*beta[3] + X[x,3]*beta[4]
}
Yp <- exp(Yp)/(1+exp(Yp))
Yp_binary <- matrix(0,X,1)
for (j in 1:length(Yp)){
Yp_binary[j] <- rbernoulli(1, p = Yp[j])
}
D[i,] <- calc_stats(exp(Yp)/(1+exp(Yp)))
}
names <- c("Mean", "Variance")
for(j in 1:2){
pval <- mean(D[,j]>D0[j])
hist(D[,j],breaks=25,xlim=range(D[,j]) + 1*c(-1,1),
xlab=names[j],
main=paste0("Bayesian p-value = ",round(pval,2)))
abline(v=D0[j],lwd=2,col=2)
}
for (i in 1:S){
beta <- samps[i,]
Yp <- matrix(0,X,1)
for (x in 1:nrow(X)){
Yp[x] <- beta[1] + X[x,1]*beta[2] + X[x,2]*beta[3] + X[x,3]*beta[4]
}
Yp <- exp(Yp)/(1+exp(Yp))
Yp_binary <- matrix(0,X,1)
for (j in 1:length(Yp)){
Yp_binary[j] <- rbernoulli(1, p = Yp[j])
}
D[i,] <- calc_stats(Yp_binary)
}
names <- c("Mean", "Variance")
for(j in 1:2){
pval <- mean(D[,j]>D0[j])
hist(D[,j],breaks=25,xlim=range(D[,j]) + 1*c(-1,1),
xlab=names[j],
main=paste0("Bayesian p-value = ",round(pval,2)))
abline(v=D0[j],lwd=2,col=2)
}
summary(Y)
summary(as.factor(Y))
summary(as.factor(Y))[1]
library(rjags)
library(geoR)
library(purrr)
Y   <- gambia$pos
X   <- gambia[,4:8]
X   <- scale(X)
mod <- textConnection("model{
for(i in 1:n){
Y[i] ~ dbern(pi[i])
logit(pi[i]) <- beta[1] + X[i,1]*beta[2] +
X[i,2]*beta[3] + X[i,3]*beta[4] +
X[i,4]*beta[5] + X[i,5]*beta[6]
}
for(j in 1:6){beta[j] ~ dnorm(0,0.01)}
}")
data  <- list(Y=Y,X=X,n=length(Y))
model <- jags.model(mod,data = data, n.chains=2,quiet=TRUE)
update(model, 5000, progress.bar="none")
samps <- coda.samples(model, variable.names=c("beta"),
n.iter=10000, progress.bar="none")
samps <- rbind(samps[[1]], samps[[2]])
S <- nrow(samps)
calc_stats <- function(data){
return(c(mean(data),var(data),summary(as.factor(data))[1]))
}
D0 <- calc_stats(Y)
D <- matrix(0,S,3)
for (i in 1:S){
beta <- samps[i,]
Yp <- matrix(0,X,1)
for (x in 1:nrow(X)){
Yp[x] <- beta[1] + X[x,1]*beta[2] + X[x,2]*beta[3] + X[x,3]*beta[4]
}
Yp <- exp(Yp)/(1+exp(Yp))
Yp_binary <- matrix(0,X,1)
for (j in 1:length(Yp)){
Yp_binary[j] <- rbernoulli(1, p = Yp[j])
}
D[i,] <- calc_stats(Yp_binary)
}
names <- c("Mean", "Variance", "Number w/o Malaria")
for(j in 1:3){
pval <- mean(D[,j]>D0[j])
hist(D[,j],breaks=25,xlim=range(D[,j]) + 2*c(-1,1),
xlab=names[j],
main=paste0("Bayesian p-value = ",round(pval,2)))
abline(v=D0[j],lwd=2,col=2)
}
Y   <- gambia$pos
X   <- gambia[,c(4,5,7)]
X   <- scale(X)
mod <- textConnection("model{
for(i in 1:n){
Y[i] ~ dbern(pi[i])
logit(pi[i]) <- beta[1] + X[i,1]*beta[2] +
X[i,2]*beta[3] + X[i,3]*beta[4]
}
for(j in 1:4){beta[j] ~ dnorm(0,0.01)}
}")
data  <- list(Y=Y,X=X,n=length(Y))
model <- jags.model(mod,data = data, n.chains=2,quiet=TRUE)
update(model, 1000, progress.bar="none")
samps <- coda.samples(model, variable.names=c("beta"),
n.iter=10000, progress.bar="none")
samps <- rbind(samps[[1]], samps[[2]])
S <- nrow(samps)
calc_stats <- function(data){
return(c(mean(data),var(data),summary(as.factor(data))[1]))
}
D0 <- calc_stats(Y)
D <- matrix(0,S,3)
for (i in 1:S){
beta <- samps[i,]
Yp <- matrix(0,X,1)
for (x in 1:nrow(X)){
Yp[x] <- beta[1] + X[x,1]*beta[2] + X[x,2]*beta[3] + X[x,3]*beta[4]
}
Yp <- exp(Yp)/(1+exp(Yp))
Yp_binary <- matrix(0,X,1)
for (j in 1:length(Yp)){
Yp_binary[j] <- rbernoulli(1, p = Yp[j])
}
D[i,] <- calc_stats(Yp_binary)
}
names <- c("Mean", "Variance", "Number w/o Malaria")
for(j in 1:3){
pval <- mean(D[,j]>D0[j])
hist(D[,j],breaks=25,xlim=range(D[,j]) + 2*c(-1,1),
xlab=names[j],
main=paste0("Bayesian p-value = ",round(pval,2)))
abline(v=D0[j],lwd=2,col=2)
}
x = seq(0,1,0.01)
y = runif(length(x), 0, 0.000001)
plot(x, y)
y = dunif(length(x), 0, 0.000001)
plot(x, y)
y = punif(length(x), 0, 0.000001)
plot(x, y)
y = dunif(x, 0, 0.000001)
plot(x, y)
y = dunif(x, 0.99999,1)
plot(x, y)
knitr::opts_chunk$set(fig.pos = "!h", out.extra = "", echo = TRUE, warning = FALSE, message = FALSE)
evi_db <- read.csv('EVI_Data.csv')
wf_db <- read.csv("All_Payment_Methods052222.csv")
ch_db <- read.csv("Chase PDM Jan - May 2022.csv")
ch_db <- read.csv("Chase PDM Jan - May 2022.CSV")
wf_db <- read.csv("All_Payment_Methods052222.csv")
library(bnlearn)
# setwd("C:/Users/squar/OneDrive - North Carolina State University/Research/Code/BBN/country_breakdown/")
setwd("~/OneDrive - North Carolina State University/Research/Code/BBN/country_breakdown/")
setwd("~/Documents/hydraulic_ABM/Input Files/")
# Call all functions and install necessary packages ---------
# package installation
source(file = './package_installation.R')
# load all written functions
source(file = './functions.R')
# Read dataset -------------
db <- read.xlsx('./data_file_reduced.xlsx')
# remove descriptive rows
db <- db[-c(1:3),]
db_x <- data.frame(lapply(db[,1:110], as.factor))
# setwd("C:/Users/squar/OneDrive - North Carolina State University/Research/Code/BBN/country_breakdown/")
setwd("~/OneDrive - North Carolina State University/Research/Code/BBN/country_breakdown/")
# Call all functions and install necessary packages ---------
# package installation
source(file = './package_installation.R')
# load all written functions
source(file = './functions.R')
# Read dataset -------------
db <- read.xlsx('./data_file_reduced.xlsx')
# remove descriptive rows
db <- db[-c(1:3),]
db_x <- data.frame(lapply(db[,1:110], as.factor))
#### ABM ####
items <- c('FinitePool_1', 'MediaExp_5', 'DemEdu', 'DemHealthcare', 'MediaExp_7',
'Longitude_3', 'Personal_7', 'MediaExp_3', 'Trustingroups_5',
'Personal_5', 'Ethnic.min', 'FinitePool_4', 'SARS', 'KnowledgeCert_2',
'Trustingroups_2', 'DemGen', 'COVIDexp', 'Longitude_2', 'quota_age',
'FinitePool_5', 'Trustingroups_4', 'Friends_7', 'Vaccine_2')
#### ABM ####
items <- c('FinitePool_1', 'MediaExp_5', 'DemEdu', 'DemHealthcare', 'MediaExp_7',
'Longitude_3', 'Personal_7', 'MediaExp_3', 'Trustingroups_5',
'Personal_5', 'Ethnic.min', 'FinitePool_4', 'SARS', 'KnowledgeCert_2',
'Trustingroups_2', 'DemGen', 'COVIDexp', 'Longitude_2', 'quota_age',
'FinitePool_5', 'Trustingroups_4', 'Friends_7', 'Vaccine_2'
'COVIDeffect_4')
#### ABM ####
items <- c('FinitePool_1', 'MediaExp_5', 'DemEdu', 'DemHealthcare', 'MediaExp_7',
'Longitude_3', 'Personal_7', 'MediaExp_3', 'Trustingroups_5',
'Personal_5', 'Ethnic.min', 'FinitePool_4', 'SARS', 'KnowledgeCert_2',
'Trustingroups_2', 'DemGen', 'COVIDexp', 'Longitude_2', 'quota_age',
'FinitePool_5', 'Trustingroups_4', 'Friends_7', 'Vaccine_2',
'COVIDeffect_4')
model_list <- '[work_from_home]'
for (item in items){
model_list <- paste0(model_list, '[', item, '|work_from_home]')
}
db_y <- read.csv("prep_split.csv")
df_y <- data.frame(lapply(db_y[,11:12], as.factor))
colnames(df_y) <- c("cook_home_more", "work_from_home")
df_tot <- cbind(db_x[items], df_y['work_from_home'], db_x['Survey_round'])
df_tot <- subset(df_tot, Survey_round == 1)
df_tot <- subset(df_tot, select=-c(Survey_round))
df_tot <- cleaning(df_tot)
dag_abm <- model2network(model_list)
fitted_abm = bn.fit(dag_abm, subset(df_tot, select=c(items, 'work_from_home')))
class_variable <- 'work_from_home'
class_level <- '2'
learned_model <- function(data){
# input args of prediction model
args_list <- list(fitted, data = data,  node = class_variable, n = 500, method = "bayes-lw", prob = T)
do.call(predict, args = args_list)
}
predictive_model <- function(data){
prediction <-  attr(learned_model(data),'prob')[class_level,]
}
performance_fun(df_tot, predictive_model,
class_variable = class_variable,
class_level = class_level)
# load all written functions
source(file = './functions.R')
# Call all functions and install necessary packages ---------
# package installation
source(file = './package_installation.R')
class_variable <- 'work_from_home'
class_level <- '2'
learned_model <- function(data){
# input args of prediction model
args_list <- list(fitted, data = data,  node = class_variable, n = 500, method = "bayes-lw", prob = T)
do.call(predict, args = args_list)
}
predictive_model <- function(data){
prediction <-  attr(learned_model(data),'prob')[class_level,]
}
performance_fun(df_tot, predictive_model,
class_variable = class_variable,
class_level = class_level)
View(df_tot)
View(fitted_abm)
class_variable <- 'work_from_home'
class_level <- '2'
learned_model <- function(data){
# input args of prediction model
args_list <- list(fitted_abm, data = data,  node = class_variable, n = 500, method = "bayes-lw", prob = T)
do.call(predict, args = args_list)
}
predictive_model <- function(data){
prediction <-  attr(learned_model(data),'prob')[class_level,]
}
performance_fun(df_tot, predictive_model,
class_variable = class_variable,
class_level = class_level)
write.bif("data_driven_wfh.bif", fitted_abm)
db_abm <- db_x[items]
db_abm <- subset(db_x, Survey_round == 1)
db_abm <- db_abm[items]
db_abm <- cleaning(db_abm)
setwd("~/Documents/hydraulic_ABM/Input Files")
write.csv("data_driven_wfh.csv", db_abm)
write.csv(db_abm, "data_driven_wfh.csv")
write.bif("data_driven_wfh.bif", fitted_abm)
nodes(fitted_abm)
nodes(fitted_abm)["Ethnic.min"] = "Ethnicmin"
abm_nodes <- nodes(fitted_abm)
abm_nodes[6] <- "Ethnicmin"
abm_nodes
nodes(fitted_abm) <- abm_nodes
abm_names = colnames(db_abm)
abm_names
abm_names[11] <- "Ethnicmin"
colnames(db_abm) <- abm_names
write.csv(db_abm, "data_driven_wfh.csv")
write.bif("data_driven_wfh.bif", fitted_abm)
