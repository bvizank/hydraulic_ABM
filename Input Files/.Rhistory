}
legend("topleft", legend = clutch$player, col=cols, lwd=2)
View(results)
library(RColorBrewer)
clutch <- data.frame(
player = c("westbrook", "harden", "leonard","james","thomas","curry","antetokounmpo",
"wall","davis","durant"),
makes = c(64,72,55,27,75,24,28,66,40,13),
attempts = c(75,95,63,39,83,26,41,82,54,16)
)
plot(0, 0, xlim = c(0,1), ylim = c(0,15), type = "n",
xlab = "Clutch Success Probability", ylab = "Posterior Probability")
x_val <- seq(0,1,0.001)
cols <- brewer.pal(name="Paired", n = 10)
results <- data.frame(matrix(ncol = 4, nrow = 10))
colnames(results) <- c("Player", "theta MAP", "Upper 95% Interval", "Lower 95% Interval")
for (i in 1:nrow(clutch)){
A <- clutch[i,2] + 1
B <- clutch[i,3] - clutch[i,2] + 1
curr_posterior <- dbeta(x_val, A, B)
lines(x_val, curr_posterior, col = cols[i], type = "l")
theta_map <- x_val[which.max(curr_posterior)]
ci95perc_u <- round(qbeta(0.975,A,B),2)
ci95perc_l <- round(qbeta(0.025,A,B),2)
results[i,] <- c(clutch[i,1], theta_map, ci95perc_u, ci95perc_l)
}
legend("topleft", legend = clutch$player, col=cols, lwd=2)
View(results)
library(RColorBrewer)
clutch <- data.frame(
player = c("westbrook", "harden", "leonard","james","thomas","curry","antetokounmpo",
"wall","davis","durant"),
makes = c(64,72,55,27,75,24,28,66,40,13),
attempts = c(75,95,63,39,83,26,41,82,54,16)
)
plot(0, 0, xlim = c(0,1), ylim = c(0,15), type = "n",
xlab = "Clutch Success Probability", ylab = "Posterior Probability")
x_val <- seq(0,1,0.001)
cols <- brewer.pal(name="Paired", n = 10)
results <- data.frame(matrix(ncol = 4, nrow = 10))
colnames(results) <- c("Player", "theta MAP", "Upper 95% Interval", "Lower 95% Interval")
for (i in 1:nrow(clutch)){
A <- clutch[i,2] + 1
B <- clutch[i,3] - clutch[i,2] + 1
curr_posterior <- dbeta(x_val, A, B)
lines(x_val, curr_posterior, col = cols[i], type = "l")
theta_map <- x_val[which.max(curr_posterior)]
ci95perc_u <- round(qbeta(0.975,A,B),2)
ci95perc_l <- round(qbeta(0.025,A,B),2)
results[i,] <- c(clutch[i,1], theta_map, ci95perc_u, ci95perc_l)
}
legend("topleft", legend = clutch$player, col=cols, lwd=2)
kable(results)
library(RColorBrewer)
library(knitr)
clutch <- data.frame(
player = c("westbrook", "harden", "leonard","james","thomas","curry","antetokounmpo",
"wall","davis","durant"),
makes = c(64,72,55,27,75,24,28,66,40,13),
attempts = c(75,95,63,39,83,26,41,82,54,16)
)
plot(0, 0, xlim = c(0,1), ylim = c(0,15), type = "n",
xlab = "Clutch Success Probability", ylab = "Posterior Probability")
x_val <- seq(0,1,0.001)
cols <- brewer.pal(name="Paired", n = 10)
results <- data.frame(matrix(ncol = 4, nrow = 10))
colnames(results) <- c("Player", "theta MAP", "Upper 95% Interval", "Lower 95% Interval")
for (i in 1:nrow(clutch)){
A <- clutch[i,2] + 1
B <- clutch[i,3] - clutch[i,2] + 1
curr_posterior <- dbeta(x_val, A, B)
lines(x_val, curr_posterior, col = cols[i], type = "l")
theta_map <- x_val[which.max(curr_posterior)]
ci95perc_u <- round(qbeta(0.975,A,B),2)
ci95perc_l <- round(qbeta(0.025,A,B),2)
results[i,] <- c(clutch[i,1], theta_map, ci95perc_u, ci95perc_l)
}
legend("topleft", legend = clutch$player, col=cols, lwd=2)
kable(results)
View(results)
knitr::opts_chunk$set(echo = TRUE)
#### Separate data for x and y ####
library(MASS)
data(Boston)
Y <- Boston$medv[c(1:500)]
Y_pred <- Boston$medv[c(501:506)]
X <- Boston[,1:13]
X <- scale(X)
X <- cbind(1,X)
X_pred <- X[c(501:506),]
X <- X[c(1:500),]
data <- list(Y=Y,X=X,n=length(Y),p=ncol(X),X_pred=X_pred,n_pred=6)
#### Define model for JAGS ####
model_string <- textConnection("model{
# Likelihood
for(i in 1:n){
Y[i] ~ dnorm(inprod(X[i,],beta[]),tau)
}
# Priors
for(j in 1:p){beta[j] ~ dnorm(0, 0.0001)}
tau ~ dgamma(0.01,0.01)
# Predictions
for (i in 1:n_pred){
Y_pred[i] ~ dnorm(inprod(X_pred[i,],beta[]),tau)
}
}")
#### Initialize model with values of theta = Y/n ####
# inits <- list(theta=y/n)
model <- jags.model(model_string,data = data,n.chains=2,quiet=TRUE)
#### Separate data for x and y ####
library(rjags)
library(MASS)
data(Boston)
Y <- Boston$medv[c(1:500)]
Y_pred <- Boston$medv[c(501:506)]
X <- Boston[,1:13]
X <- scale(X)
X <- cbind(1,X)
X_pred <- X[c(501:506),]
X <- X[c(1:500),]
data <- list(Y=Y,X=X,n=length(Y),p=ncol(X),X_pred=X_pred,n_pred=6)
#### Define model for JAGS ####
model_string <- textConnection("model{
# Likelihood
for(i in 1:n){
Y[i] ~ dnorm(inprod(X[i,],beta[]),tau)
}
# Priors
for(j in 1:p){beta[j] ~ dnorm(0, 0.0001)}
tau ~ dgamma(0.01,0.01)
# Predictions
for (i in 1:n_pred){
Y_pred[i] ~ dnorm(inprod(X_pred[i,],beta[]),tau)
}
}")
#### Initialize model with values of theta = Y/n ####
# inits <- list(theta=y/n)
model <- jags.model(model_string,data = data,n.chains=2,quiet=TRUE)
#### Burn-in 10000 samples ####
update(model, 10000, progress.bar="none")
#### Run 10000 samples, outputing each of the beta parameters ####
params  <- c("beta", "Y_pred")
samples <- coda.samples(model,
variable.names=params,
n.iter=10000, progress.bar="none")
out <- summary(samples)$statistics
names_X <- c("Y501", "Y502", "Y503", "Y504", "Y505", "Y506", "Intercept",
"Crime Rate", "Large Res. Zoned", "% Industrial",
"Charles River Border", "NOx Conc.", "Rms/Dwelling", "% Built < 1940",
"Dis. To Hub", "Highway Accessibility", "Tax Rate", "Pupil/Teacher",
"% Black", "Pop. Status")
rownames(out) <- names_X
out
Y_pred
pbeta(10,1)
pbeta(0.7,10,1)
plot(seq(0,1,0.01),dbeta(seq(0,1,0.01),10,1))
1 - pbeta(0.7,10,1)
0.972/0.0282
knitr::opts_chunk$set(echo = TRUE)
library(rjags)
library(geoR)
Y   <- gambia$pos
X   <- gambia[,4:8]
X   <- scale(X)
mod <- textConnection("model{
for(i in 1:n){
Y[i] ~ dbern(pi[i])
logit(pi[i]) <- beta[1] + X[i,1]*beta[2] +
X[i,2]*beta[3] + X[i,3]*beta[4] +
X[i,4]*beta[5] + X[i,5]*beta[6]
}
for(j in 1:6){beta[j] ~ dnorm(0,0.01)}
}")
data  <- list(Y=Y,X=X,n=length(Y))
model <- jags.model(mod,data = data, n.chains=2,quiet=TRUE)
update(model, 5000, progress.bar="none")
samps <- coda.samples(model, variable.names=c("beta"),
n.iter=10000, progress.bar="none")
samps <- rbind(samps[[1]], samps[[2]])
S <- nrow(samps)
calc_stats <- function(data){
return(c(mean(data),var(data)))
}
D0 <- calc_stats(Y)
D <- matrix(0,S,2)
for (i in 1:S){
beta <- samps[i,]
Yp <- matrix(0,X,1)
for (x in 1:nrow(X)){
Yp[x] <- beta[1] + X[x,1]*beta[2] + X[x,2]*beta[3] + X[x,3]*beta[4] + X[x,4]*beta[5] + X[x,5]*beta[6]
}
D[s,] <- calc_stats(Yp)
}
for (i in 1:S){
beta <- samps[i,]
Yp <- matrix(0,X,1)
for (x in 1:nrow(X)){
Yp[x] <- beta[1] + X[x,1]*beta[2] + X[x,2]*beta[3] + X[x,3]*beta[4] + X[x,4]*beta[5] + X[x,5]*beta[6]
}
D[i,] <- calc_stats(Yp)
}
View(D)
names <- c("Mean", "Variance")
for(j in 1:6){
pval <- mean(D[,j]>D0[j])
hist(D[,j],breaks=25,xlim=range(D[,j]) + 1*c(-1,1),
xlab=names[j],
main=paste0("Bayesian p-value = ",round(pval,2)))
abline(v=D0[j],lwd=2,col=2)
}
for(j in 1:2){
pval <- mean(D[,j]>D0[j])
hist(D[,j],breaks=25,xlim=range(D[,j]) + 1*c(-1,1),
xlab=names[j],
main=paste0("Bayesian p-value = ",round(pval,2)))
abline(v=D0[j],lwd=2,col=2)
}
Y   <- gambia$pos
X   <- gambia[,c(4,5,7)]
X   <- scale(X)
mod <- textConnection("model{
for(i in 1:n){
Y[i] ~ dbern(pi[i])
logit(pi[i]) <- beta[1] + X[i,1]*beta[2] +
X[i,2]*beta[3] + X[i,3]*beta[4] +
X[i,4]*beta[5] + X[i,5]*beta[6]
}
for(j in 1:6){beta[j] ~ dnorm(0,0.01)}
}")
data  <- list(Y=Y,X=X,n=length(Y))
model <- jags.model(mod,data = data, n.chains=2,quiet=TRUE)
Y   <- gambia$pos
X   <- gambia[,c(4,5,7)]
X   <- scale(X)
mod <- textConnection("model{
for(i in 1:n){
Y[i] ~ dbern(pi[i])
logit(pi[i]) <- beta[1] + X[i,1]*beta[2] +
X[i,2]*beta[3] + X[i,3]*beta[4]
}
for(j in 1:4){beta[j] ~ dnorm(0,0.01)}
}")
data  <- list(Y=Y,X=X,n=length(Y))
model <- jags.model(mod,data = data, n.chains=2,quiet=TRUE)
update(model, 1000, progress.bar="none")
samps <- coda.samples(model, variable.names=c("beta"),
n.iter=10000, progress.bar="none")
samps <- rbind(samps[[1]], samps[[2]])
S <- nrow(samps)
calc_stats <- function(data){
return(c(mean(data),var(data)))
}
D0 <- calc_stats(Y)
D <- matrix(0,S,2)
for (i in 1:S){
beta <- samps[i,]
Yp <- matrix(0,X,1)
for (x in 1:nrow(X)){
Yp[x] <- beta[1] + X[x,1]*beta[2] + X[x,2]*beta[3] + X[x,3]*beta[4] + X[x,4]*beta[5] + X[x,5]*beta[6]
}
D[i,] <- calc_stats(Yp)
}
Y   <- gambia$pos
X   <- gambia[,c(4,5,7)]
X   <- scale(X)
mod <- textConnection("model{
for(i in 1:n){
Y[i] ~ dbern(pi[i])
logit(pi[i]) <- beta[1] + X[i,1]*beta[2] +
X[i,2]*beta[3] + X[i,3]*beta[4]
}
for(j in 1:4){beta[j] ~ dnorm(0,0.01)}
}")
data  <- list(Y=Y,X=X,n=length(Y))
model <- jags.model(mod,data = data, n.chains=2,quiet=TRUE)
update(model, 1000, progress.bar="none")
samps <- coda.samples(model, variable.names=c("beta"),
n.iter=10000, progress.bar="none")
samps <- rbind(samps[[1]], samps[[2]])
S <- nrow(samps)
calc_stats <- function(data){
return(c(mean(data),var(data)))
}
D0 <- calc_stats(Y)
D <- matrix(0,S,2)
for (i in 1:S){
beta <- samps[i,]
Yp <- matrix(0,X,1)
for (x in 1:nrow(X)){
Yp[x] <- beta[1] + X[x,1]*beta[2] + X[x,2]*beta[3] + X[x,3]*beta[4]
}
D[i,] <- calc_stats(Yp)
}
names <- c("Mean", "Variance")
for(j in 1:2){
pval <- mean(D[,j]>D0[j])
hist(D[,j],breaks=25,xlim=range(D[,j]) + 1*c(-1,1),
xlab=names[j],
main=paste0("Bayesian p-value = ",round(pval,2)))
abline(v=D0[j],lwd=2,col=2)
}
View(samps)
D0 <- calc_stats(logit(Y))
D0 <- calc_stats(log(Y/(1-Y)))
Y/(1-Y)
expit(D)
exp(D)
D <- matrix(0,S,2)
for (i in 1:S){
beta <- samps[i,]
Yp <- matrix(0,X,1)
for (x in 1:nrow(X)){
Yp[x] <- beta[1] + X[x,1]*beta[2] + X[x,2]*beta[3] + X[x,3]*beta[4]
}
D[i,] <- calc_stats(exp(Yp)/(1+exp(Yp)))
}
D0 <- calc_stats(Y)
names <- c("Mean", "Variance")
for(j in 1:2){
pval <- mean(D[,j]>D0[j])
hist(D[,j],breaks=25,xlim=range(D[,j]) + 1*c(-1,1),
xlab=names[j],
main=paste0("Bayesian p-value = ",round(pval,2)))
abline(v=D0[j],lwd=2,col=2)
}
for (i in 1:S){
beta <- samps[i,]
Yp <- matrix(0,X,1)
for (x in 1:nrow(X)){
Yp[x] <- beta[1] + X[x,1]*beta[2] + X[x,2]*beta[3] + X[x,3]*beta[4]
}
Yp <- exp(Yp)/(1+exp(Yp))
Yp_binary <- matrix(0,X,1)
for (j in 1:nrow(Yp)){
Yp_binary[j] <- rbernoulli(1, p = Yp[j])
}
D[i,] <- calc_stats(exp(Yp)/(1+exp(Yp)))
}
for (i in 1:S){
beta <- samps[i,]
Yp <- matrix(0,X,1)
for (x in 1:nrow(X)){
Yp[x] <- beta[1] + X[x,1]*beta[2] + X[x,2]*beta[3] + X[x,3]*beta[4]
}
Yp <- exp(Yp)/(1+exp(Yp))
Yp_binary <- matrix(0,X,1)
for (j in 1:length(Yp)){
Yp_binary[j] <- rbernoulli(1, p = Yp[j])
}
D[i,] <- calc_stats(exp(Yp)/(1+exp(Yp)))
}
library(purrr)
for (i in 1:S){
beta <- samps[i,]
Yp <- matrix(0,X,1)
for (x in 1:nrow(X)){
Yp[x] <- beta[1] + X[x,1]*beta[2] + X[x,2]*beta[3] + X[x,3]*beta[4]
}
Yp <- exp(Yp)/(1+exp(Yp))
Yp_binary <- matrix(0,X,1)
for (j in 1:length(Yp)){
Yp_binary[j] <- rbernoulli(1, p = Yp[j])
}
D[i,] <- calc_stats(exp(Yp)/(1+exp(Yp)))
}
names <- c("Mean", "Variance")
for(j in 1:2){
pval <- mean(D[,j]>D0[j])
hist(D[,j],breaks=25,xlim=range(D[,j]) + 1*c(-1,1),
xlab=names[j],
main=paste0("Bayesian p-value = ",round(pval,2)))
abline(v=D0[j],lwd=2,col=2)
}
for (i in 1:S){
beta <- samps[i,]
Yp <- matrix(0,X,1)
for (x in 1:nrow(X)){
Yp[x] <- beta[1] + X[x,1]*beta[2] + X[x,2]*beta[3] + X[x,3]*beta[4]
}
Yp <- exp(Yp)/(1+exp(Yp))
Yp_binary <- matrix(0,X,1)
for (j in 1:length(Yp)){
Yp_binary[j] <- rbernoulli(1, p = Yp[j])
}
D[i,] <- calc_stats(Yp_binary)
}
names <- c("Mean", "Variance")
for(j in 1:2){
pval <- mean(D[,j]>D0[j])
hist(D[,j],breaks=25,xlim=range(D[,j]) + 1*c(-1,1),
xlab=names[j],
main=paste0("Bayesian p-value = ",round(pval,2)))
abline(v=D0[j],lwd=2,col=2)
}
summary(Y)
summary(as.factor(Y))
summary(as.factor(Y))[1]
library(rjags)
library(geoR)
library(purrr)
Y   <- gambia$pos
X   <- gambia[,4:8]
X   <- scale(X)
mod <- textConnection("model{
for(i in 1:n){
Y[i] ~ dbern(pi[i])
logit(pi[i]) <- beta[1] + X[i,1]*beta[2] +
X[i,2]*beta[3] + X[i,3]*beta[4] +
X[i,4]*beta[5] + X[i,5]*beta[6]
}
for(j in 1:6){beta[j] ~ dnorm(0,0.01)}
}")
data  <- list(Y=Y,X=X,n=length(Y))
model <- jags.model(mod,data = data, n.chains=2,quiet=TRUE)
update(model, 5000, progress.bar="none")
samps <- coda.samples(model, variable.names=c("beta"),
n.iter=10000, progress.bar="none")
samps <- rbind(samps[[1]], samps[[2]])
S <- nrow(samps)
calc_stats <- function(data){
return(c(mean(data),var(data),summary(as.factor(data))[1]))
}
D0 <- calc_stats(Y)
D <- matrix(0,S,3)
for (i in 1:S){
beta <- samps[i,]
Yp <- matrix(0,X,1)
for (x in 1:nrow(X)){
Yp[x] <- beta[1] + X[x,1]*beta[2] + X[x,2]*beta[3] + X[x,3]*beta[4]
}
Yp <- exp(Yp)/(1+exp(Yp))
Yp_binary <- matrix(0,X,1)
for (j in 1:length(Yp)){
Yp_binary[j] <- rbernoulli(1, p = Yp[j])
}
D[i,] <- calc_stats(Yp_binary)
}
names <- c("Mean", "Variance", "Number w/o Malaria")
for(j in 1:3){
pval <- mean(D[,j]>D0[j])
hist(D[,j],breaks=25,xlim=range(D[,j]) + 2*c(-1,1),
xlab=names[j],
main=paste0("Bayesian p-value = ",round(pval,2)))
abline(v=D0[j],lwd=2,col=2)
}
Y   <- gambia$pos
X   <- gambia[,c(4,5,7)]
X   <- scale(X)
mod <- textConnection("model{
for(i in 1:n){
Y[i] ~ dbern(pi[i])
logit(pi[i]) <- beta[1] + X[i,1]*beta[2] +
X[i,2]*beta[3] + X[i,3]*beta[4]
}
for(j in 1:4){beta[j] ~ dnorm(0,0.01)}
}")
data  <- list(Y=Y,X=X,n=length(Y))
model <- jags.model(mod,data = data, n.chains=2,quiet=TRUE)
update(model, 1000, progress.bar="none")
samps <- coda.samples(model, variable.names=c("beta"),
n.iter=10000, progress.bar="none")
samps <- rbind(samps[[1]], samps[[2]])
S <- nrow(samps)
calc_stats <- function(data){
return(c(mean(data),var(data),summary(as.factor(data))[1]))
}
D0 <- calc_stats(Y)
D <- matrix(0,S,3)
for (i in 1:S){
beta <- samps[i,]
Yp <- matrix(0,X,1)
for (x in 1:nrow(X)){
Yp[x] <- beta[1] + X[x,1]*beta[2] + X[x,2]*beta[3] + X[x,3]*beta[4]
}
Yp <- exp(Yp)/(1+exp(Yp))
Yp_binary <- matrix(0,X,1)
for (j in 1:length(Yp)){
Yp_binary[j] <- rbernoulli(1, p = Yp[j])
}
D[i,] <- calc_stats(Yp_binary)
}
names <- c("Mean", "Variance", "Number w/o Malaria")
for(j in 1:3){
pval <- mean(D[,j]>D0[j])
hist(D[,j],breaks=25,xlim=range(D[,j]) + 2*c(-1,1),
xlab=names[j],
main=paste0("Bayesian p-value = ",round(pval,2)))
abline(v=D0[j],lwd=2,col=2)
}
x = seq(0,1,0.01)
y = runif(length(x), 0, 0.000001)
plot(x, y)
y = dunif(length(x), 0, 0.000001)
plot(x, y)
y = punif(length(x), 0, 0.000001)
plot(x, y)
y = dunif(x, 0, 0.000001)
plot(x, y)
y = dunif(x, 0.99999,1)
plot(x, y)
knitr::opts_chunk$set(fig.pos = "!h", out.extra = "", echo = TRUE, warning = FALSE, message = FALSE)
evi_db <- read.csv('EVI_Data.csv')
wf_db <- read.csv("All_Payment_Methods052222.csv")
ch_db <- read.csv("Chase PDM Jan - May 2022.csv")
ch_db <- read.csv("Chase PDM Jan - May 2022.CSV")
wf_db <- read.csv("All_Payment_Methods052222.csv")
setwd("~/Documents/hydraulic_ABM/Input Files")
library(bnlearn)
read.bif("pmt_ppe.bif")
fitted <- read.bif("pmt_ppe.bif")
fitted.nodes
